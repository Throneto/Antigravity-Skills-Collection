#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å­¦ä¹ å™¨ V2 Enhanced - ä½¿ç”¨AIå­¦ä¹ çš„æ™ºèƒ½è§„åˆ™
åŸºäºä»30ä¸ªæ ·æœ¬ä¸­å­¦ä¹ çš„ enhanced_rules.jsonï¼Œå®ç°æ™ºèƒ½åˆ†ç±»å’Œæå–
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from element_db import ElementDB
from txt_to_json_converter import TxtToJsonConverter


class EnhancedRulesEngine:
    """æ™ºèƒ½è§„åˆ™å¼•æ“ - åŸºäºAIå­¦ä¹ çš„è§„åˆ™"""

    def __init__(self, rules_path: str = "/tmp/enhanced_rules.json"):
        with open(rules_path, 'r', encoding='utf-8') as f:
            self.rules = json.load(f)

        self.domain_rules = self.rules['domain_classification_rules']
        self.complexity_rules = self.rules['complexity_detection_rules']
        self.extraction_patterns = self.rules['extraction_patterns']
        self.quality_rules = self.rules['quality_assessment_rules']

    def classify_domain(self, prompt_data: Dict) -> Tuple[str, float, str]:
        """
        æ™ºèƒ½é¢†åŸŸåˆ†ç±»ï¼ˆä½¿ç”¨è¯­ä¹‰è§„åˆ™ï¼‰

        Returns:
            (primary_domain, confidence, reasoning)
        """
        original = prompt_data.get('original_prompt', '')
        theme = prompt_data.get('theme', '')
        mode = prompt_data.get('mode', 'generate')
        category = prompt_data.get('category', '')

        full_text = f"{theme} {original} {category}".lower()

        scores = {}

        for domain, rules in self.domain_rules.items():
            score = 0
            matches = []

            # æ£€æŸ¥è¯­ä¹‰æŒ‡æ ‡
            for indicator_group in rules['semantic_indicators']:
                if any(keyword in full_text for keyword in indicator_group.lower().split('ã€')):
                    score += 3
                    matches.append(indicator_group[:20])

            # æ£€æŸ¥æ¨¡å¼åå¥½
            if mode in rules.get('mode_preference', []):
                score += 1

            # æ£€æŸ¥åˆ†ç±»æ ‡ç­¾
            for tag in rules.get('category_tags', []):
                if tag in category or tag in theme:
                    score += 2
                    matches.append(f"tag:{tag}")

            if score > 0:
                scores[domain] = {
                    'score': score,
                    'matches': matches,
                    'threshold': rules.get('confidence_threshold', 0.7)
                }

        if not scores:
            return 'portrait', 0.3, 'fallback default'

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„é¢†åŸŸ
        top_domain = max(scores.items(), key=lambda x: x[1]['score'])
        domain_name = top_domain[0]
        domain_data = top_domain[1]

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = min(1.0, domain_data['score'] / 10.0)

        # ç”Ÿæˆæ¨ç†è¯´æ˜
        reasoning = f"matched: {', '.join(domain_data['matches'][:3])}"

        return domain_name, confidence, reasoning

    def calculate_complexity(self, prompt_data: Dict) -> Tuple[str, float]:
        """
        è®¡ç®—æç¤ºè¯å¤æ‚åº¦

        Returns:
            (complexity_level, complexity_score)
        """
        original = prompt_data.get('original_prompt', '')
        modules = prompt_data.get('modules', {})

        score = self.complexity_rules['complexity_scoring']['base_score']

        # é•¿åº¦åŠ åˆ†
        length = len(original)
        length_bonus = (length / 100) * self.complexity_rules['complexity_scoring']['length_bonus']['per_100_chars']
        length_bonus = min(length_bonus, self.complexity_rules['complexity_scoring']['length_bonus']['max_bonus'])
        score += length_bonus

        # ç»“æ„åŠ åˆ†
        structure_bonus = self.complexity_rules['complexity_scoring']['structure_bonus']
        if '{' in original or 'json' in original.lower():
            score += structure_bonus.get('has_json', 0)
        if 'æ­¥éª¤' in original or 'è¦æ±‚' in original or 'ï¼š' in original:
            score += structure_bonus.get('has_steps', 0)
        if any(marker in original for marker in ['å‚æ•°', 'è®¾ç½®', 'é…ç½®', 'è§„æ ¼']):
            score += structure_bonus.get('has_parameters', 0)

        # æŠ€æœ¯å‚æ•°åŠ åˆ†
        technical_bonus = self.complexity_rules['complexity_scoring']['technical_bonus']
        if any(cam in original for cam in ['ç´¢å°¼', '85mm', 'f/', 'å…‰åœˆ', 'å¿«é—¨']):
            score += technical_bonus.get('camera_params', 0)
        if any(light in original for light in ['ä¸‰ç‚¹å¼', 'è½®å»“å…‰', 'ä½“ç§¯å…‰', 'æŸ”å…‰', 'ç¡¬å…‰']):
            score += technical_bonus.get('lighting_details', 0)
        if any(engine in original for engine in ['c4d', 'Cinema 4D', 'è™šå¹»å¼•æ“', 'UE5']):
            score += technical_bonus.get('render_engine', 0)

        # ç¡®å®šå¤æ‚åº¦ç­‰çº§
        if score >= 8.0:
            level = 'complex'
        elif score >= 6.0:
            level = 'medium'
        else:
            level = 'simple'

        return level, round(score, 2)

    def should_use_skill(self, complexity_score: float, confidence: float,
                        prompt_data: Dict) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨Skillå¤„ç†

        Returns:
            (should_use_skill, reason)
        """
        routing_rules = self.quality_rules['skill_routing_rules']
        original = prompt_data.get('original_prompt', '')

        # å¿…é¡»ä½¿ç”¨Skillçš„æƒ…å†µ
        if complexity_score >= 8.0:
            return True, f"high_complexity:{complexity_score}"
        if '{' in original and 'json' in original.lower():
            return True, "contains_json_structure"
        if 'æ­¥éª¤1' in original or 'ä¸€ã€' in original:
            return True, "multi_step_system"

        # åˆ†ç±»ä¸æ¸…æ™°çš„æƒ…å†µ
        if confidence < 0.7:
            return True, f"low_confidence:{confidence}"

        # é»˜è®¤ä½¿ç”¨Pythonï¼ˆåŒ…æ‹¬ä¸­ç­‰å¤æ‚åº¦ï¼‰
        return False, f"python_processing:{complexity_score},{confidence}"

    def extract_elements(self, prompt_data: Dict, domain: str) -> List[Dict]:
        """
        åŸºäºè§„åˆ™æå–å…ƒç´ 

        Returns:
            List of extracted elements
        """
        if domain not in self.extraction_patterns:
            return []

        pattern = self.extraction_patterns[domain]
        original = prompt_data.get('original_prompt', '')
        modules = prompt_data.get('modules', {})

        elements = []

        for category in pattern.get('primary_categories', []):
            extraction_rule = pattern.get('extraction_rules', {}).get(category)
            if not extraction_rule:
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„æŒ‡æ ‡
            indicators = extraction_rule.get('indicators', [])
            matched_content = []

            for indicator in indicators:
                if indicator in original:
                    matched_content.append(indicator)

            # ä»modulesä¸­æŸ¥æ‰¾ç›¸å…³æ•°æ®
            module_data = modules.get(category, modules.get(category.replace('_', ' '), []))
            if isinstance(module_data, list):
                for item in module_data[:3]:  # æœ€å¤šæå–3ä¸ª
                    if isinstance(item, str) and len(item) > 10:
                        matched_content.append(item)

            if not matched_content:
                continue

            # ç”Ÿæˆå…ƒç´ 
            for content in matched_content[:2]:  # æ¯ä¸ªç±»åˆ«æœ€å¤š2ä¸ª
                element = self._create_element(
                    category=category,
                    content=content,
                    extraction_rule=extraction_rule,
                    domain=domain
                )
                if element:
                    elements.append(element)

        return elements

    def _create_element(self, category: str, content: str,
                       extraction_rule: Dict, domain: str) -> Optional[Dict]:
        """åˆ›å»ºå•ä¸ªå…ƒç´ """
        # ç®€åŒ–åç§°
        name = self._simplify_name(content)

        # ç”Ÿæˆä¸­æ–‡å
        chinese_name = content[:15] if len(content) < 30 else content[:12] + "..."

        # ç”Ÿæˆkeywords
        keywords = self._extract_keywords(content)

        # ç”Ÿæˆai_prompt_template
        template_pattern = extraction_rule.get('template_pattern', '{content}')
        ai_prompt_template = content[:100]  # ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨å†…å®¹

        # ç”Ÿæˆreusability_score
        score_range = extraction_rule.get('reusability_score_range', [7.0, 8.0])
        reusability_score = (score_range[0] + score_range[1]) / 2

        return {
            'category': category,
            'name': name,
            'chinese_name': chinese_name,
            'ai_prompt_template': ai_prompt_template,
            'keywords': keywords,
            'reusability': reusability_score
        }

    def _simplify_name(self, text: str) -> str:
        """ç®€åŒ–åç§°ä¸ºæ ‡è¯†ç¬¦"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        name = re.sub(r'[^\w\s-]', '', text.lower())
        # æ›¿æ¢ç©ºæ ¼å’Œè¿å­—ç¬¦ä¸ºä¸‹åˆ’çº¿
        name = re.sub(r'[-\s]+', '_', name)
        # æˆªæ–­åˆ°åˆç†é•¿åº¦
        return name[:50] if name else 'unnamed'

    def _extract_keywords(self, text: str, max_keywords: int = 5) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•å®ç°ï¼šåˆ†è¯åå–å‰å‡ ä¸ª
        words = re.findall(r'[\w]+', text)
        keywords = []
        for word in words:
            if len(word) > 2:  # å¿½ç•¥å¤ªçŸ­çš„è¯
                keywords.append(word)
            if len(keywords) >= max_keywords:
                break
        return keywords


class BatchLearnerV2Enhanced:
    """å¢å¼ºç‰ˆæ‰¹é‡å­¦ä¹ å™¨ - ä½¿ç”¨AIå­¦ä¹ çš„è§„åˆ™"""

    def __init__(self, db_path: str = "extracted_results/elements.db",
                 rules_path: str = "/tmp/enhanced_rules.json"):
        self.db = ElementDB(db_path)
        self.rules_engine = EnhancedRulesEngine(rules_path)
        self.txt_converter = TxtToJsonConverter()

        self.stats = {
            'total_files': 0,
            'processed': 0,
            'skipped': 0,
            'python_processed': 0,
            'skill_needed': 0,
            'total_elements': 0,
            'by_domain': {},
            'by_complexity': {'simple': 0, 'medium': 0, 'complex': 0},
            'skill_review_list': []
        }

    def load_prompt_file(self, file_path: Path) -> Dict:
        """åŠ è½½æç¤ºè¯æ–‡ä»¶ï¼ˆæ”¯æŒJSONå’ŒTXTï¼‰"""
        try:
            # å°è¯•JSONæ ¼å¼
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data
        except json.JSONDecodeError:
            # TXTæ ¼å¼
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    txt_content = f.read()
                    return self.txt_converter.convert_txt_to_prompt_data(
                        txt_content,
                        file_path.name
                    )
            except Exception as e:
                raise Exception(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")

    def learn_from_directory(self, directory: str, dry_run: bool = False) -> Dict:
        """
        ä»ç›®å½•æ‰¹é‡å­¦ä¹ ï¼ˆä½¿ç”¨æ™ºèƒ½è§„åˆ™ï¼‰

        Args:
            directory: æç¤ºè¯æ–‡ä»¶ç›®å½•
            dry_run: é¢„æ¼”æ¨¡å¼ï¼Œåªåˆ†æä¸å­¦ä¹ 
        """
        dir_path = Path(directory)
        if not dir_path.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")

        # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶
        txt_files = list(dir_path.glob("*.txt"))
        json_files = list(dir_path.glob("*.json"))
        all_files = txt_files + json_files

        self.stats['total_files'] = len(all_files)

        print(f"\n{'='*80}")
        print(f"ğŸ“š æ‰¹é‡å­¦ä¹ å™¨ V2 Enhanced - æ™ºèƒ½è§„åˆ™ç‰ˆæœ¬")
        print(f"{'='*80}")
        print(f"ç›®å½•: {directory}")
        print(f"æ–‡ä»¶æ€»æ•°: {len(all_files)} (TXT: {len(txt_files)}, JSON: {len(json_files)})")
        print(f"è§„åˆ™æ¥æº: enhanced_rules.json (ä»30ä¸ªæ ·æœ¬å­¦ä¹ )")
        print(f"æ¨¡å¼: {'ğŸ” é¢„æ¼”æ¨¡å¼' if dry_run else 'ğŸ¤– æ™ºèƒ½å¤„ç†æ¨¡å¼'}")
        print(f"{'='*80}\n")

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for idx, file_path in enumerate(all_files, 1):
            print(f"\n[{idx}/{len(all_files)}] {file_path.name}")

            try:
                # åŠ è½½æ–‡ä»¶
                prompt_data = self.load_prompt_file(file_path)
                prompt_data['prompt_id'] = idx  # ä¸´æ—¶ID

                # æ­¥éª¤1: æ™ºèƒ½é¢†åŸŸåˆ†ç±»
                domain, confidence, reasoning = self.rules_engine.classify_domain(prompt_data)
                print(f"  ğŸ“‚ Domain: {domain} (confidence: {confidence:.0%}, {reasoning})")

                # æ­¥éª¤2: è®¡ç®—å¤æ‚åº¦
                complexity, score = self.rules_engine.calculate_complexity(prompt_data)
                print(f"  ğŸ“Š Complexity: {complexity} (score: {score}/10)")

                # æ­¥éª¤3: åˆ¤æ–­å¤„ç†æ–¹å¼
                use_skill, skill_reason = self.rules_engine.should_use_skill(
                    score, confidence, prompt_data
                )

                if use_skill:
                    print(f"  ğŸ¤– â†’ Route to SKILL ({skill_reason})")
                    self.stats['skill_needed'] += 1
                    self.stats['skill_review_list'].append({
                        'file': file_path.name,
                        'domain': domain,
                        'complexity': complexity,
                        'score': score,
                        'reason': skill_reason,
                        'prompt_id': idx
                    })
                else:
                    print(f"  ğŸ â†’ Python processing ({skill_reason})")

                    if not dry_run:
                        # Pythonæ™ºèƒ½æå–
                        elements = self.rules_engine.extract_elements(prompt_data, domain)

                        # ä¿å­˜åˆ°æ•°æ®åº“
                        added = 0
                        for element in elements:
                            success = self._add_element_to_db(
                                element, domain, idx, file_path.name
                            )
                            if success:
                                added += 1

                        self.stats['total_elements'] += added
                        print(f"  âœ… Extracted: {len(elements)} elements, Added: {added}")

                    self.stats['python_processed'] += 1

                # æ›´æ–°ç»Ÿè®¡
                self.stats['processed'] += 1
                self.stats['by_domain'][domain] = self.stats['by_domain'].get(domain, 0) + 1
                self.stats['by_complexity'][complexity] += 1

            except Exception as e:
                print(f"  âŒ Error: {str(e)}")
                self.stats['skipped'] += 1

        # ç”ŸæˆæŠ¥å‘Š
        return self._generate_report(dry_run)

    def _add_element_to_db(self, element: Dict, domain: str,
                          prompt_id: int, source_file: str) -> bool:
        """æ·»åŠ å…ƒç´ åˆ°æ•°æ®åº“"""
        try:
            # ç”Ÿæˆelement_id
            element_id = self._generate_element_id(domain, element['category'])

            # ç”Ÿæˆtags
            tags = [domain, element['category']] + element.get('keywords', [])[:3]

            # æ·»åŠ åˆ°æ•°æ®åº“
            success = self.db.add_element(
                element_id=element_id,
                domain_id=domain,
                category_id=element['category'],
                name=element['name'],
                chinese_name=element.get('chinese_name'),
                ai_prompt_template=element['ai_prompt_template'],
                keywords=element.get('keywords', []),
                tags=list(set(tags))[:10],
                reusability_score=element.get('reusability', 7.0),
                source_prompts=[prompt_id],
                learned_from='batch_learner_v2_enhanced',
                metadata={'source_file': source_file}
            )

            return success

        except Exception as e:
            return False

    def _generate_element_id(self, domain_id: str, category_id: str) -> str:
        """ç”Ÿæˆå…ƒç´ ID"""
        cursor = self.db.conn.cursor()
        cursor.execute("""
            SELECT element_id FROM elements
            WHERE domain_id = ? AND category_id = ?
            ORDER BY element_id DESC
            LIMIT 1
        """, (domain_id, category_id))

        last = cursor.fetchone()
        if last:
            match = re.search(r'_(\d+)$', last[0])
            num = int(match.group(1)) + 1 if match else 1
        else:
            num = 1

        return f"{domain_id}_{category_id}_{num:03d}"

    def _generate_report(self, dry_run: bool) -> Dict:
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ‰¹é‡å¤„ç†æŠ¥å‘Š (V2 Enhanced)")
        print(f"{'='*80}\n")

        print(f"æ–‡ä»¶å¤„ç†ï¼š")
        print(f"  æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"  æˆåŠŸå¤„ç†: {self.stats['processed']}")
        print(f"  è·³è¿‡: {self.stats['skipped']}")
        print()

        print(f"å¤„ç†æ–¹å¼åˆ†å¸ƒï¼š")
        print(f"  ğŸ Pythonå¤„ç†: {self.stats['python_processed']}")
        print(f"  ğŸ¤– éœ€è¦Skill: {self.stats['skill_needed']}")
        print(f"  æ¯”ä¾‹: {self.stats['python_processed']}/{self.stats['skill_needed']}")
        print()

        print(f"é¢†åŸŸåˆ†å¸ƒï¼š")
        for domain, count in sorted(self.stats['by_domain'].items(),
                                    key=lambda x: x[1], reverse=True):
            print(f"  â€¢ {domain}: {count} ä¸ª")
        print()

        print(f"å¤æ‚åº¦åˆ†å¸ƒï¼š")
        for level, count in self.stats['by_complexity'].items():
            print(f"  â€¢ {level}: {count} ä¸ª")
        print()

        if not dry_run and self.stats['python_processed'] > 0:
            print(f"å…ƒç´ æå–ï¼š")
            print(f"  æ–°å¢å…ƒç´ : {self.stats['total_elements']}")
            print(f"  å¹³å‡æ¯ä¸ª: {self.stats['total_elements'] / self.stats['python_processed']:.1f}")
            print()

        if self.stats['skill_needed'] > 0:
            # ä¿å­˜éœ€è¦Skillå¤„ç†çš„åˆ—è¡¨
            skill_list_path = '/tmp/need_skill_review.json'
            with open(skill_list_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'total': self.stats['skill_needed'],
                    'generated_at': datetime.now().isoformat(),
                    'items': self.stats['skill_review_list']
                }, f, ensure_ascii=False, indent=2)

            print(f"éœ€è¦Skillå¤„ç†çš„æ¡ˆä¾‹ ({self.stats['skill_needed']}ä¸ª)ï¼š")
            for item in self.stats['skill_review_list'][:10]:
                print(f"  â€¢ {item['file']}: {item['complexity']}({item['score']}) - {item['reason']}")
            if len(self.stats['skill_review_list']) > 10:
                print(f"  ... è¿˜æœ‰ {len(self.stats['skill_review_list']) - 10} ä¸ª")
            print(f"\n  å·²ä¿å­˜åˆ°: {skill_list_path}")
            print()

        print(f"{'='*80}\n")

        return {
            'stats': self.stats,
            'skill_list_path': '/tmp/need_skill_review.json' if self.stats['skill_needed'] > 0 else None
        }

    def close(self):
        """å…³é—­æ•°æ®åº“"""
        self.db.close()


# å‘½ä»¤è¡Œä½¿ç”¨
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='æ‰¹é‡å­¦ä¹  V2 Enhanced (æ™ºèƒ½è§„åˆ™ç‰ˆ)')
    parser.add_argument('directory', help='æç¤ºè¯æ–‡ä»¶ç›®å½•')
    parser.add_argument('--dry-run', action='store_true', help='é¢„æ¼”æ¨¡å¼')
    parser.add_argument('--db', default='extracted_results/elements.db', help='æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--rules', default='/tmp/enhanced_rules.json', help='è§„åˆ™æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # æ£€æŸ¥è§„åˆ™æ–‡ä»¶
    if not Path(args.rules).exists():
        print(f"\nâš ï¸  é”™è¯¯: è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {args.rules}")
        print("è¯·å…ˆè¿è¡Œé˜¶æ®µ1ç”Ÿæˆ enhanced_rules.json\n")
        exit(1)

    learner = BatchLearnerV2Enhanced(args.db, args.rules)

    try:
        report = learner.learn_from_directory(
            directory=args.directory,
            dry_run=args.dry_run
        )

        # å¯¼å‡ºæ•°æ®åº“
        if not args.dry_run and report['stats']['python_processed'] > 0:
            learner.db.export_to_json('extracted_results/universal_elements_library.json')
            print("âœ… å·²å¯¼å‡ºåˆ° universal_elements_library.json")

    finally:
        learner.close()
