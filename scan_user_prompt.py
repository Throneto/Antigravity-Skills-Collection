#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æ‰«æç”¨æˆ·æä¾›çš„prompt"""

from learner import HybridLearner
from smart_reviewer import SmartReviewer
import json

# è¯»å–prompt
with open('test_user_prompt.txt', 'r') as f:
    prompt_text = f.read()

print("="*70)
print("  ğŸ” æ‰«æç”¨æˆ·Prompt - é«˜çº§æ—¶å°šè‚–åƒ")
print("="*70)
print(f"\nğŸ“ Prompté•¿åº¦: {len(prompt_text)} å­—ç¬¦\n")

# åˆå§‹åŒ–å­¦ä¹ å™¨
learner = HybridLearner()
reviewer = SmartReviewer()

# æå–ç‰¹å¾
print("ğŸ” æ­¥éª¤ 1: ç‰¹å¾æå–...\n")
result = learner.extract_and_classify(prompt_text)

print(f"âœ… æ£€æµ‹åˆ° {result['total_detected']} ä¸ªç‰¹å¾")
print(f"   æ–°ç‰¹å¾: {len(result['new_features'])} ä¸ª")
print(f"   å·²å­˜åœ¨: {len(result['existing_features'])} ä¸ª\n")

if result['new_features']:
    print("="*70)
    print("  ğŸ“‹ æ–°ç‰¹å¾è¯¦æƒ…")
    print("="*70)

    # æŒ‰ç±»åˆ«åˆ†ç»„
    by_category = {}
    for feature in result['new_features']:
        cat = feature['category']
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(feature)

    for category, features in sorted(by_category.items()):
        print(f"\nã€{category}ã€‘ ({len(features)} ä¸ª)")
        for idx, feature in enumerate(features, 1):
            print(f"  {idx}. {feature.get('raw_text', '')}")
            print(f"     ç½®ä¿¡åº¦: {feature.get('confidence', 0)*100:.0f}% | æ–¹æ³•: {feature.get('method', 'unknown')}")

    # æ™ºèƒ½å®¡æ ¸
    print("\n" + "="*70)
    print("  ğŸ¤– æ­¥éª¤ 2: æ™ºèƒ½å®¡æ ¸")
    print("="*70 + "\n")

    review_results = reviewer.batch_review(result['new_features'])

    print(f"ğŸ“Š å®¡æ ¸ç»“æœ:")
    print(f"   ğŸ‰ è‡ªåŠ¨æ‰¹å‡† (â‰¥90%): {len(review_results['auto_approve'])} ä¸ª")
    print(f"   ğŸ¤” éœ€è¦å®¡æ ¸ (70-90%): {len(review_results['manual_review'])} ä¸ª")
    print(f"   âš ï¸  ä½ç½®ä¿¡åº¦ (50-70%): {len(review_results['low_confidence'])} ä¸ª")
    print(f"   âŒ å»ºè®®æ‹’ç» (<50%): {len(review_results['auto_reject'])} ä¸ª\n")

    # è‡ªåŠ¨æ‰¹å‡†çš„
    if review_results['auto_approve']:
        print("="*70)
        print("ğŸ‰ è‡ªåŠ¨æ‰¹å‡†çš„ç‰¹å¾ï¼ˆå¯ç›´æ¥æ·»åŠ åˆ°åº“ï¼‰:")
        print("="*70)
        for analysis in review_results['auto_approve']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nâœ… [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")
            scores_detail = analysis['scores']
            print(f"   è¯¦ç»†è¯„åˆ†:")
            print(f"     - è§„åˆ™è´¨é‡: {scores_detail['rule_quality']*100:.0f}%")
            print(f"     - æè¿°è´¨é‡: {scores_detail['description_quality']*100:.0f}%")
            print(f"     - å¤ç”¨æ€§: {scores_detail['reusability']*100:.0f}%")
            print(f"     - ç±»åˆ«é‡è¦æ€§: {scores_detail['importance']*100:.0f}%")

    # éœ€è¦äººå·¥å®¡æ ¸çš„
    if review_results['manual_review']:
        print("\n" + "="*70)
        print("ğŸ¤” éœ€è¦äººå·¥å®¡æ ¸çš„ç‰¹å¾:")
        print("="*70)
        for analysis in review_results['manual_review']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nğŸŸ¡ [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")
            print(f"   å»ºè®®: {analysis['reason']}")

    # ä½ç½®ä¿¡åº¦çš„
    if review_results['low_confidence']:
        print("\n" + "="*70)
        print("âš ï¸  ä½ç½®ä¿¡åº¦ç‰¹å¾ï¼ˆå»ºè®®ä»”ç»†å®¡æ ¸ï¼‰:")
        print("="*70)
        for analysis in review_results['low_confidence']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nâš ï¸  [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")

else:
    print("â„¹ï¸  æœªå‘ç°æ–°ç‰¹å¾ï¼ˆæ‰€æœ‰ç‰¹å¾éƒ½å·²å­˜åœ¨äºåº“ä¸­ï¼‰\n")

# æ˜¾ç¤ºå·²å­˜åœ¨çš„ç‰¹å¾
if result['existing_features']:
    print("\n" + "="*70)
    print(f"  âœ… å·²å­˜åœ¨çš„ç‰¹å¾ ({len(result['existing_features'])} ä¸ª)")
    print("="*70)

    existing_by_cat = {}
    for feature in result['existing_features']:
        cat = feature['category']
        if cat not in existing_by_cat:
            existing_by_cat[cat] = []
        existing_by_cat[cat].append(feature.get('raw_text', ''))

    for category, texts in sorted(existing_by_cat.items()):
        print(f"\nã€{category}ã€‘: {', '.join(texts[:3])}" + (f" ...ç­‰{len(texts)}ä¸ª" if len(texts) > 3 else ""))

print("\n" + "="*70)
print("  âœ… æ‰«æå®Œæˆ")
print("="*70)

# æ€»ç»“
print("\nğŸ’¡ æ€»ç»“:")
print(f"   â€¢ è¿™ä¸ªpromptéå¸¸è¯¦ç»†ï¼ŒåŒ…å«{result['total_detected']}ä¸ªå¯è¯†åˆ«ç‰¹å¾")
print(f"   â€¢ å…¶ä¸­{len(result['new_features'])}ä¸ªæ˜¯æ–°ç‰¹å¾ï¼Œå¯ä»¥æ·»åŠ åˆ°åº“ä¸­")
if review_results['auto_approve']:
    print(f"   â€¢ {len(review_results['auto_approve'])}ä¸ªç‰¹å¾è¾¾åˆ°è‡ªåŠ¨æ‰¹å‡†æ ‡å‡†ï¼ˆâ‰¥90åˆ†ï¼‰")
if review_results['manual_review']:
    print(f"   â€¢ {len(review_results['manual_review'])}ä¸ªç‰¹å¾éœ€è¦äººå·¥å®¡æ ¸ï¼ˆ70-90åˆ†ï¼‰")

print("\nğŸš€ ä¸‹ä¸€æ­¥:")
print("   å¦‚æœè¦æ·»åŠ è¿™äº›ç‰¹å¾åˆ°åº“ï¼Œè¿è¡Œ:")
print("   python3 auto_learn_workflow.py scan \"$(cat test_user_prompt.txt)\"")
print()
