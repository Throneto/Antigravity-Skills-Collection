#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­¦ä¹ å•ä¸ªæç¤ºè¯ - Universal Learner
"""

import json
from element_db import ElementDB
from datetime import datetime


def learn_pencil_sketch_idol():
    """å­¦ä¹  pencil_sketch_idol æç¤ºè¯å¹¶æå–å…ƒç´ """

    # è¯»å–å·²æå–çš„æ•°æ®
    with open('extracted_results/pencil_sketch_idol_extracted.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    # åˆå§‹åŒ–æ•°æ®åº“
    db = ElementDB("extracted_results/elements.db")

    # Step 1: é¢†åŸŸåˆ†ç±»
    primary_domain = "art"
    secondary_domain = "common"

    print("ğŸ¯ Step 1: é¢†åŸŸåˆ†ç±»")
    print(f"  ä¸»é¢†åŸŸ: {primary_domain} (è‰ºæœ¯é£æ ¼)")
    print(f"  æ¬¡é¢†åŸŸ: {secondary_domain} (é€šç”¨æŠ€æœ¯)")
    print()

    # Step 2: æå–å¯å¤ç”¨å…ƒç´ 
    # ä» "what_works" éƒ¨åˆ†æå–æœ‰ä»·å€¼çš„å…ƒç´ 
    elements_to_extract = []

    # å…ƒç´ 1: å¯¹æ¯”æ„å›¾æ¦‚å¿µ
    elements_to_extract.append({
        "element_id": "art_composition_concepts_001",
        "domain_id": "art",
        "category_id": "art_composition_concepts",
        "name": "sketch_vs_reference_comparison",
        "chinese_name": "ç´ æä¸å‚ç…§å¯¹æ¯”æ„å›¾",
        "ai_prompt_template": "pencil sketch on paper with reference photo displayed beside it, showing comparison between drawing and original",
        "keywords": json.dumps(["comparison", "sketch", "reference", "side_by_side", "art_process"]),
        "reusability_score": 7.0,
        "confidence_score": 0.85,
        "source_prompts": json.dumps(["pencil_sketch_idol_001"]),
        "learned_from": "prompt_extractor_analysis",
        "metadata": json.dumps({
            "concept": "å¯¹æ¯”æ„å›¾ - å±•ç¤ºåˆ›ä½œè¿‡ç¨‹",
            "applications": ["è‰ºæœ¯æ•™ç¨‹", "è¿‡ç¨‹å±•ç¤º", "æŠ€èƒ½æ¼”ç¤º"],
            "example": "3D graphite pencil sketch on {surface} depicting {subject}, with {reference object} showing original photo for comparison",
            "note": "ä»Dçº§åé¢æ•™æä¸­æå–çš„æ ¸å¿ƒæ¦‚å¿µ"
        })
    })

    # å…ƒç´ 2: è‰ºæœ¯å·¥ä½œç©ºé—´åœºæ™¯
    elements_to_extract.append({
        "element_id": "art_scene_settings_001",
        "domain_id": "art",
        "category_id": "art_scene_settings",
        "name": "artist_workspace_with_reference",
        "chinese_name": "è‰ºæœ¯å®¶å·¥ä½œç©ºé—´ï¼ˆå¸¦å‚ç…§ç‰©ï¼‰",
        "ai_prompt_template": "artist's workspace scene, top-down view, showing creative process with reference materials",
        "keywords": json.dumps(["workspace", "artist", "creative_process", "top_down_view", "reference_materials"]),
        "reusability_score": 8.0,
        "confidence_score": 0.80,
        "source_prompts": json.dumps(["pencil_sketch_idol_001"]),
        "learned_from": "prompt_extractor_analysis",
        "metadata": json.dumps({
            "scene_type": "å·¥ä½œç©ºé—´å±•ç¤º",
            "perspective": "top-down or slight angle",
            "elements": ["notebook/paper", "reference device", "drawing tools"],
            "mood": "meticulous, perfectionist, comparative"
        })
    })

    # å…ƒç´ 3: è¶…å†™å®ç´ æé£æ ¼
    elements_to_extract.append({
        "element_id": "art_art_styles_001",
        "domain_id": "art",
        "category_id": "art_art_styles",
        "name": "hyper_realistic_graphite_sketch",
        "chinese_name": "è¶…å†™å®çŸ³å¢¨ç´ æ",
        "ai_prompt_template": "hyper-realistic 3D graphite pencil sketch, photorealistic pencil work, trompe-l'oeil effect",
        "keywords": json.dumps(["hyper_realistic", "graphite", "pencil_sketch", "photorealistic", "trompe_loeil", "3d_effect"]),
        "reusability_score": 8.5,
        "confidence_score": 0.90,
        "source_prompts": json.dumps(["pencil_sketch_idol_001"]),
        "learned_from": "prompt_extractor_analysis",
        "metadata": json.dumps({
            "art_style": "è¶…å†™å®ä¸»ä¹‰ç´ æ",
            "medium": "graphite pencil",
            "era": "contemporary realism",
            "technique": "3D rendering simulation of traditional drawing",
            "aesthetic": ["photorealistic", "detailed pencil work", "trompe-l'oeil"]
        })
    })

    # å…ƒç´ 4: çº¹ç†çº¸å¼ æè´¨
    elements_to_extract.append({
        "element_id": "common_material_textures_001",
        "domain_id": "common",
        "category_id": "common_material_textures",
        "name": "textured_white_notebook_paper",
        "chinese_name": "çº¹ç†ç™½è‰²ç¬”è®°æœ¬çº¸",
        "ai_prompt_template": "textured white notebook paper with clear paper quality, delicate details, subtle imperfections",
        "keywords": json.dumps(["paper_texture", "white_paper", "notebook", "subtle_imperfections", "organic_texture"]),
        "reusability_score": 7.5,
        "confidence_score": 0.85,
        "source_prompts": json.dumps(["pencil_sketch_idol_001"]),
        "learned_from": "prompt_extractor_analysis",
        "metadata": json.dumps({
            "material": "paper",
            "color": "white",
            "texture": "textured, subtle imperfections",
            "quality": "clear, detailed",
            "applications": ["ç´ æèƒŒæ™¯", "ç¬”è®°å±•ç¤º", "æ‰‹å†™å†…å®¹"]
        })
    })

    # å…ƒç´ 5: è‡ªç„¶å…‰åå°„æ•ˆæœ
    elements_to_extract.append({
        "element_id": "common_lighting_techniques_001",
        "domain_id": "common",
        "category_id": "common_lighting_techniques",
        "name": "soft_sunlight_reflections_on_glass",
        "chinese_name": "ç»ç’ƒè¡¨é¢æŸ”å’Œé˜³å…‰åå°„",
        "ai_prompt_template": "natural reflections and soft sunlight reflections on glass, soft diffused daylight",
        "keywords": json.dumps(["natural_light", "reflections", "glass", "soft_sunlight", "diffused_light"]),
        "reusability_score": 8.0,
        "confidence_score": 0.85,
        "source_prompts": json.dumps(["pencil_sketch_idol_001"]),
        "learned_from": "prompt_extractor_analysis",
        "metadata": json.dumps({
            "lighting_type": "natural daylight",
            "quality": "soft, diffused",
            "effect": "reflections on glass surface",
            "time_of_day": "daytime",
            "applications": ["äº§å“æ‘„å½±", "é™ç‰©", "ç»ç’ƒå™¨çš¿"]
        })
    })

    print("ğŸ“¦ Step 2: æå–å…ƒç´ ")
    print(f"  ä»åé¢æ•™æä¸­è¯†åˆ«çš„å¯å¤ç”¨å…ƒç´ : {len(elements_to_extract)}ä¸ª")
    print()

    # Step 3: åˆ›å»ºç±»åˆ«ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    cursor = db.conn.cursor()

    categories_to_create = [
        ("art_composition_concepts", "art", "æ„å›¾æ¦‚å¿µ", "è‰ºæœ¯æ„å›¾çš„æ ¸å¿ƒæ¦‚å¿µå’Œå¸ƒå±€ç­–ç•¥"),
        ("art_scene_settings", "art", "åœºæ™¯è®¾å®š", "è‰ºæœ¯åˆ›ä½œçš„åœºæ™¯å’Œç¯å¢ƒè®¾å®š"),
        ("art_art_styles", "art", "è‰ºæœ¯é£æ ¼", "å„ç§è‰ºæœ¯æµæ´¾å’Œè¡¨ç°é£æ ¼"),
        ("common_material_textures", "common", "æè´¨çº¹ç†", "å„ç§æè´¨çš„çº¹ç†å’Œè´¨æ„Ÿæè¿°"),
        ("common_lighting_techniques", "common", "å…‰ç…§æŠ€æœ¯", "æ‘„å½±å’Œæ¸²æŸ“ä¸­çš„å…‰ç…§æŠ€å·§")
    ]

    for cat_id, domain, name, desc in categories_to_create:
        cursor.execute("""
        INSERT OR IGNORE INTO categories (category_id, domain_id, name, description, total_elements)
        VALUES (?, ?, ?, ?, ?)
        """, (cat_id, domain, name, desc, 0))

    db.conn.commit()

    # Step 4: æ’å…¥å…ƒç´ åˆ°æ•°æ®åº“
    print("ğŸ’¾ Step 3-5: æ’å…¥å…ƒç´ åˆ°æ•°æ®åº“")

    for elem in elements_to_extract:
        cursor.execute("""
        INSERT OR REPLACE INTO elements (
            element_id, domain_id, category_id,
            name, chinese_name,
            ai_prompt_template, keywords,
            reusability_score, confidence_score,
            source_prompts, learned_from,
            metadata, created_at, updated_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            elem["element_id"],
            elem["domain_id"],
            elem["category_id"],
            elem["name"],
            elem["chinese_name"],
            elem["ai_prompt_template"],
            elem["keywords"],
            elem["reusability_score"],
            elem["confidence_score"],
            elem["source_prompts"],
            elem["learned_from"],
            elem["metadata"],
            datetime.now().isoformat(),
            datetime.now().isoformat()
        ))

        # æ·»åŠ æ ‡ç­¾
        keywords = json.loads(elem["keywords"])
        for keyword in keywords:
            cursor.execute("""
            INSERT OR IGNORE INTO tags (tag_name, tag_type, usage_count)
            VALUES (?, ?, ?)
            """, (keyword, "element_keyword", 0))

            cursor.execute("SELECT tag_id FROM tags WHERE tag_name = ?", (keyword,))
            tag_id = cursor.fetchone()[0]

            cursor.execute("""
            INSERT OR IGNORE INTO element_tags (element_id, tag_id)
            VALUES (?, ?)
            """, (elem["element_id"], tag_id))

            cursor.execute("""
            UPDATE tags SET usage_count = usage_count + 1
            WHERE tag_id = ?
            """, (tag_id,))

        print(f"  âœ… {elem['element_id']}")
        print(f"     {elem['chinese_name']} (å¤ç”¨æ€§: {elem['reusability_score']}/10)")

    # æ›´æ–°ç±»åˆ«ç»Ÿè®¡
    for cat_id, _, _, _ in categories_to_create:
        cursor.execute("""
        UPDATE categories
        SET total_elements = (SELECT COUNT(*) FROM elements WHERE category_id = ?)
        WHERE category_id = ?
        """, (cat_id, cat_id))

    # æ›´æ–°é¢†åŸŸç»Ÿè®¡
    for domain in ["art", "common"]:
        cursor.execute("""
        UPDATE domains
        SET total_elements = (SELECT COUNT(*) FROM elements WHERE domain_id = ?),
            updated_at = ?
        WHERE domain_id = ?
        """, (domain, datetime.now().isoformat(), domain))

    db.conn.commit()

    print()
    print("ğŸ“Š Step 6: å­¦ä¹ æŠ¥å‘Š")
    print("-" * 60)

    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    stats = {}
    for domain in ["art", "common"]:
        cursor.execute("SELECT total_elements FROM domains WHERE domain_id = ?", (domain,))
        result = cursor.fetchone()
        stats[domain] = result[0] if result else 0

    print(f"âœ… å·²æ·»åŠ åˆ°æ•°æ®åº“: {len(elements_to_extract)}ä¸ªæ–°å…ƒç´ ")
    print()
    print("ğŸ’¾ æ•°æ®åº“ç»Ÿè®¡:")
    print(f"  - arté¢†åŸŸ: {stats.get('art', 0)}ä¸ªå…ƒç´ ")
    print(f"  - commoné¢†åŸŸ: {stats.get('common', 0)}ä¸ªå…ƒç´ ")
    print()

    # è´¨é‡è¯„ä¼°
    avg_reusability = sum(e["reusability_score"] for e in elements_to_extract) / len(elements_to_extract)

    print("ğŸ’¡ è´¨é‡è¯„ä¼°:")
    print(f"  - æå–å®Œæ•´åº¦: 60% (ä»Dçº§åé¢æ•™æä¸­æå–æœ‰ä»·å€¼éƒ¨åˆ†)")
    print(f"  - å¹³å‡å¤ç”¨æ€§: {avg_reusability:.1f}/10")
    print(f"  - æ ‡ç­¾æ•°é‡: {len(set([kw for e in elements_to_extract for kw in json.loads(e['keywords'])]))}ä¸ª")
    print()
    print("âš ï¸  é‡è¦æç¤º:")
    print("  è¿™æ˜¯ä¸€ä¸ªDçº§åé¢æ•™æ(3.75/10)ï¼ŒåŒ…å«å¤§é‡é”™è¯¯:")
    print("  - 64%å†—ä½™ç‡")
    print("  - 70%æ— æ•ˆæ°´å°æŒ‡ä»¤")
    print("  - 3å¤„çŸ›ç›¾æŒ‡ä»¤")
    print()
    print("  âœ… å·²æå–çš„å…ƒç´ æ˜¯ä»'what_works'éƒ¨åˆ†è¯†åˆ«çš„æ ¸å¿ƒæ¦‚å¿µ")
    print("  âŒ å¤§éƒ¨åˆ†å†…å®¹(è´¨é‡è¯å †ç Œã€çŸ›ç›¾æŒ‡ä»¤)å·²è¢«è¿‡æ»¤ï¼Œä¸åº”å¤ç”¨")
    print()
    print("  ğŸ’¡ çœŸæ­£æœ‰ä»·å€¼çš„å­¦ä¹ æˆæœåœ¨:")
    print("  - pencil_sketch_idol_learning_report.md (793è¡Œåé¢æ•™æåˆ†æ)")
    print("  - pencil_sketch_idol_learning_cards.json (5å¼ Ankiå­¦ä¹ å¡ç‰‡)")
    print("  - meta_knowledge_extraction_report.json (9ä¸ªå…ƒçŸ¥è¯†å…ƒç´ )")
    print()
    print("-" * 60)

    db.conn.close()

    return {
        "learned_elements": len(elements_to_extract),
        "avg_reusability": avg_reusability,
        "domains": stats
    }


if __name__ == "__main__":
    print("ğŸš€ Universal Learner - å­¦ä¹ å•ä¸ªæç¤ºè¯")
    print("ğŸ“š æºPrompt: pencil_sketch_idol_001 (Dçº§åé¢æ•™æ)")
    print("=" * 60)
    print()

    result = learn_pencil_sketch_idol()

    print()
    print("ğŸ‰ å­¦ä¹ å®Œæˆ!")
