#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æµ‹è¯•æ‰«ææ–°çš„å¤æ‚Prompt"""

from learner import HybridLearner
from smart_reviewer import SmartReviewer
import json

# è¯»å–prompt
with open('test_new_prompt.txt', 'r') as f:
    prompt_text = f.read()

print("="*70)
print("  ğŸ” æ‰«ææ–°Prompt - åœ£è¯æµ·æŠ¥åˆ›æ„")
print("="*70)
print(f"\nğŸ“ Prompté•¿åº¦: {len(prompt_text)} å­—ç¬¦\n")

# åˆå§‹åŒ–å­¦ä¹ å™¨
learner = HybridLearner()
reviewer = SmartReviewer()

# æå–ç‰¹å¾
print("ğŸ” æ­¥éª¤ 1: ç‰¹å¾æå–...\n")
result = learner.extract_and_classify(prompt_text)

print(f"âœ… æ£€æµ‹åˆ° {result['total_detected']} ä¸ªç‰¹å¾")
print(f"   æ–°ç‰¹å¾: {len(result['new_features'])} ä¸ª")
print(f"   å·²å­˜åœ¨: {len(result['existing_features'])} ä¸ª\n")

if result['new_features']:
    print("="*70)
    print("  ğŸ“‹ æ–°ç‰¹å¾è¯¦æƒ…")
    print("="*70)

    for idx, feature in enumerate(result['new_features'], 1):
        print(f"\n{idx}. ç±»åˆ«: {feature['category']}")
        print(f"   æè¿°: {feature.get('raw_text', '')}")
        print(f"   ç½®ä¿¡åº¦: {feature.get('confidence', 0)*100:.0f}%")
        print(f"   æ–¹æ³•: {feature.get('method', 'unknown')}")

    # æ™ºèƒ½å®¡æ ¸
    print("\n" + "="*70)
    print("  ğŸ¤– æ­¥éª¤ 2: æ™ºèƒ½å®¡æ ¸")
    print("="*70 + "\n")

    review_results = reviewer.batch_review(result['new_features'])

    print(f"ğŸ“Š å®¡æ ¸ç»“æœ:")
    print(f"   ğŸ‰ è‡ªåŠ¨æ‰¹å‡† (â‰¥90%): {len(review_results['auto_approve'])} ä¸ª")
    print(f"   ğŸ¤” éœ€è¦å®¡æ ¸ (70-90%): {len(review_results['manual_review'])} ä¸ª")
    print(f"   âš ï¸  ä½ç½®ä¿¡åº¦ (50-70%): {len(review_results['low_confidence'])} ä¸ª")
    print(f"   âŒ å»ºè®®æ‹’ç» (<50%): {len(review_results['auto_reject'])} ä¸ª\n")

    # è‡ªåŠ¨æ‰¹å‡†çš„
    if review_results['auto_approve']:
        print("="*70)
        print("ğŸ‰ è‡ªåŠ¨æ‰¹å‡†çš„ç‰¹å¾ï¼ˆå¯ç›´æ¥æ·»åŠ åˆ°åº“ï¼‰:")
        print("="*70)
        for analysis in review_results['auto_approve']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nâœ… [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")
            print(f"   - è§„åˆ™è´¨é‡: {analysis['scores']['rule_quality']*100:.0f}%")
            print(f"   - æè¿°è´¨é‡: {analysis['scores']['description_quality']*100:.0f}%")
            print(f"   - å¤ç”¨æ€§: {analysis['scores']['reusability']*100:.0f}%")
            print(f"   - ç±»åˆ«é‡è¦æ€§: {analysis['scores']['importance']*100:.0f}%")

    # éœ€è¦äººå·¥å®¡æ ¸çš„
    if review_results['manual_review']:
        print("\n" + "="*70)
        print("ğŸ¤” éœ€è¦äººå·¥å®¡æ ¸çš„ç‰¹å¾:")
        print("="*70)
        for analysis in review_results['manual_review']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nğŸŸ¡ [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")
            print(f"   ç†ç”±: {analysis['reason']}")

    # ä½ç½®ä¿¡åº¦çš„
    if review_results['low_confidence']:
        print("\n" + "="*70)
        print("âš ï¸  ä½ç½®ä¿¡åº¦ç‰¹å¾ï¼ˆå»ºè®®ä»”ç»†å®¡æ ¸ï¼‰:")
        print("="*70)
        for analysis in review_results['low_confidence']:
            feature = analysis['feature']
            score = analysis['total_score']
            print(f"\nâš ï¸  [{feature['category']}] {feature.get('raw_text', '')}")
            print(f"   æ€»è¯„åˆ†: {score*100:.0f}%")
            print(f"   ç†ç”±: {analysis['reason']}")

else:
    print("â„¹ï¸  æœªå‘ç°æ–°ç‰¹å¾ï¼ˆæ‰€æœ‰ç‰¹å¾éƒ½å·²å­˜åœ¨äºåº“ä¸­ï¼‰\n")

print("\n" + "="*70)
print("  âœ… æ‰«æå®Œæˆ")
print("="*70)
